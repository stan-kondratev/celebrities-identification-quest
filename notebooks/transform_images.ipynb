{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"/home/jal/.deepface/weights/vgg_face_weights.h5\"\n",
    "# Load the pre-trained face detection model\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('../raw_data/shape_predictor_81_face_landmarks.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    }
   ],
   "source": [
    "folder_input_path = \"../raw_data/output_imdb_top100/\"\n",
    "folder_output_path = \"../raw_data/image_trans/\"\n",
    "\n",
    "file_list = [os.path.join(folder_input_path, file) for file in os.listdir(folder_input_path) if os.path.isfile(os.path.join(folder_input_path, file))]\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image without detected face ../raw_data/output_imdb_top100/marilyn_monroe\n",
      "Image without detected face ../raw_data/output_imdb_top100/george_c._scott\n",
      "Image without detected face ../raw_data/output_imdb_top100/kim_basinger\n",
      "Image without detected face ../raw_data/output_imdb_top100/kim_novak\n",
      "Image without detected face ../raw_data/output_imdb_top100/charles_laughton\n",
      "Image without detected face ../raw_data/output_imdb_top100/virginia_cherrill\n"
     ]
    }
   ],
   "source": [
    "images = [f.replace('.jpg', '') for f in file_list]\n",
    "for image_path in images:\n",
    "    image = cv2.imread(image_path+'.jpg')\n",
    "    # Convert the image to grayscale for face detection\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces in the image\n",
    "    faces = detector(gray)\n",
    "    # We take only the first detected face, if exist\n",
    "    if len(faces) == 0:\n",
    "         # Save the final preprocessed image\n",
    "        save_path = image_path.replace(folder_input_path,folder_output_path)+\".jpg\"\n",
    "        # black and white output:\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "        print(\"Image without detected face\", image_path)\n",
    "        continue\n",
    "    face = faces[0]\n",
    "    \n",
    "    # We extract the landmarks   \n",
    "    landmarks = predictor(image, face)\n",
    "    landmarks = np.array([[p.x, p.y] for p in landmarks.parts()])\n",
    "\n",
    "    # Calculate the center of the eyes\n",
    "    left_eye = np.mean(landmarks[36:42], axis=0)\n",
    "    right_eye = np.mean(landmarks[42:48], axis=0)\n",
    "    nose = landmarks[30]\n",
    "\n",
    "    # Calculate the angle between the eyes and the horizontal line\n",
    "    dY = right_eye[1] - left_eye[1]\n",
    "    dX = right_eye[0] - left_eye[0]\n",
    "    angle = np.degrees(np.arctan2(dY, dX))\n",
    "\n",
    "    # Rotate the image around the center of the face rectangle\n",
    "    (x, y, w, h) = (face.left(), face.top(), face.width(), face.height())\n",
    "    center = (x + w // 2, y + h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    aligned_face = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]), flags=cv2.INTER_CUBIC)\n",
    "    if ((aligned_face.shape[0] == 0) or (aligned_face.shape[1] == 0) or (aligned_face.shape[2] == 0)):\n",
    "        continue\n",
    "    \n",
    "    # Re apply the face crop on the aligned image\n",
    "    gray = cv2.cvtColor(aligned_face, cv2.COLOR_BGR2GRAY)\n",
    "    faces_aligned = detector(gray)\n",
    "    if not faces_aligned:\n",
    "        continue\n",
    "    reduce = 0.7\n",
    "    increase = 1/0.7\n",
    "    \n",
    "    x, y, w, h = int(faces_aligned[0].left()*reduce), int(faces_aligned[0].top()*reduce), int(faces_aligned[0].width()*increase), int(faces_aligned[0].height()*increase)\n",
    "    processed_face = aligned_face[y:y+h, x:x+w]\n",
    "    if ((processed_face.shape[0] == 0) or (processed_face.shape[1] == 0) or (processed_face.shape[2] == 0)):\n",
    "        continue\n",
    "    \n",
    "    # Save the final preprocessed image\n",
    "    save_path = image_path.replace(folder_input_path,folder_output_path)+\".jpg\"\n",
    "    # black and white output:\n",
    "    cv2.imwrite(save_path, cv2.cvtColor(processed_face, cv2.COLOR_BGR2GRAY)) #cv2.cvtColor(processed_face, cv2.COLOR_BGR2GRAY)\n",
    "    #cv2.imwrite(save_path, face_image)\n",
    "    # print(f\"Face image saved: {save_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To reduce the image size of all images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n",
      "270\n",
      "339\n",
      "427\n",
      "2165\n",
      "1284\n",
      "640\n",
      "680\n",
      "3186\n",
      "288\n",
      "317\n",
      "291\n",
      "4256\n",
      "1080\n",
      "1363\n",
      "1500\n",
      "1268\n",
      "2000\n",
      "300\n",
      "600\n",
      "4146\n",
      "274\n",
      "295\n",
      "324\n",
      "266\n",
      "1417\n",
      "1275\n",
      "293\n",
      "1295\n",
      "309\n",
      "2400\n",
      "399\n",
      "1363\n",
      "448\n",
      "1368\n",
      "1311\n",
      "281\n",
      "306\n",
      "1200\n",
      "281\n",
      "600\n",
      "1665\n",
      "214\n",
      "288\n",
      "1360\n",
      "1641\n",
      "600\n",
      "2667\n",
      "1371\n",
      "447\n",
      "271\n",
      "280\n",
      "2271\n",
      "2358\n",
      "289\n",
      "274\n",
      "1361\n",
      "2924\n",
      "3295\n",
      "2400\n",
      "1023\n",
      "1000\n",
      "291\n",
      "785\n",
      "1340\n",
      "1010\n",
      "515\n",
      "2000\n",
      "274\n",
      "297\n",
      "278\n",
      "1556\n",
      "289\n",
      "1403\n",
      "360\n",
      "295\n",
      "365\n",
      "1665\n",
      "1170\n",
      "595\n",
      "3795\n",
      "389\n",
      "596\n",
      "3149\n",
      "272\n",
      "1551\n",
      "1458\n",
      "408\n",
      "1976\n",
      "2400\n",
      "269\n",
      "287\n",
      "1536\n",
      "1363\n",
      "276\n",
      "360\n",
      "266\n",
      "1800\n",
      "2840\n",
      "295\n",
      "2400\n",
      "312\n",
      "1545\n",
      "1638\n",
      "288\n",
      "1689\n",
      "928\n",
      "277\n",
      "600\n",
      "602\n",
      "304\n",
      "337\n",
      "304\n",
      "5184\n",
      "1357\n",
      "1411\n",
      "2417\n",
      "1361\n",
      "600\n",
      "1435\n",
      "282\n",
      "371\n",
      "1361\n",
      "283\n",
      "1370\n",
      "1363\n",
      "300\n",
      "267\n",
      "280\n",
      "421\n",
      "1535\n",
      "1437\n",
      "1363\n",
      "1326\n",
      "1404\n",
      "1687\n",
      "1497\n",
      "1365\n",
      "1325\n",
      "298\n",
      "1419\n",
      "427\n",
      "1038\n",
      "480\n",
      "463\n",
      "279\n",
      "1464\n",
      "1362\n",
      "1365\n",
      "1638\n",
      "355\n",
      "1360\n",
      "287\n",
      "347\n",
      "1483\n",
      "339\n",
      "369\n",
      "3617\n",
      "800\n",
      "267\n",
      "1256\n",
      "600\n",
      "270\n",
      "343\n",
      "3028\n",
      "266\n",
      "640\n",
      "338\n",
      "303\n",
      "316\n",
      "1567\n",
      "319\n",
      "1671\n",
      "306\n",
      "313\n",
      "1517\n",
      "1779\n",
      "1365\n",
      "1389\n",
      "642\n",
      "1413\n",
      "1671\n",
      "834\n",
      "283\n",
      "1814\n",
      "1363\n",
      "2048\n",
      "1370\n",
      "281\n",
      "1363\n",
      "2048\n",
      "1358\n",
      "1364\n",
      "1334\n",
      "1426\n",
      "450\n",
      "304\n",
      "1363\n",
      "448\n",
      "1307\n",
      "1272\n",
      "1363\n",
      "286\n",
      "346\n",
      "645\n",
      "293\n",
      "274\n",
      "303\n",
      "355\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"../raw_data/output_imdb_top100/\"\n",
    "\n",
    "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "\n",
    "images = [f.replace('.jpg', '') for f in file_list]\n",
    "for image_path in images:\n",
    "    img = cv2.imread(image_path+'.jpg')\n",
    "    width = int(img.shape[1])\n",
    "    height = int(img.shape[0])\n",
    "    target_width = 600\n",
    "    if width > target_width:\n",
    "        dim = (target_width, int(height*(target_width/width)))\n",
    "        resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        resized = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR)\n",
    "        Image.fromarray(resized).save(image_path+'.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../raw_data/output_imdb_top100/\"\n",
    "\n",
    "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "\n",
    "file_list = [\"../raw_data/output_imdb_top100/samara_weaving.jpg\"]\n",
    "\n",
    "images = [f.replace('.jpg', '') for f in file_list]\n",
    "for image_path in images:\n",
    "    img = cv2.imread(image_path+'.jpg')\n",
    "    width = int(img.shape[1])\n",
    "    height = int(img.shape[0])\n",
    "    target_width = 600\n",
    "    if width > target_width:\n",
    "        dim = (target_width, int(height*(target_width/width)))\n",
    "        resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        resized = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR)\n",
    "        Image.fromarray(resized).save(image_path+'.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
