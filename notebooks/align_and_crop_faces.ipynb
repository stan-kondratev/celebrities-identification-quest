{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook is used for face alignment and for turning images into grayscale.\n",
    "### This improves performance of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"/home/jal/.deepface/weights/vgg_face_weights.h5\"\n",
    "# Load the pre-trained face detection model\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('../raw_data/shape_predictor_81_face_landmarks.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    }
   ],
   "source": [
    "folder_input_path = \"../raw_data/output_imdb_top100/\"\n",
    "folder_output_path = \"../raw_data/image_trans/\"\n",
    "\n",
    "file_list = [os.path.join(folder_input_path, file) for file in os.listdir(folder_input_path) if os.path.isfile(os.path.join(folder_input_path, file))]\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [f.replace('.jpg', '') for f in file_list]\n",
    "for image_path in images:\n",
    "    image = cv2.imread(image_path+'.jpg')\n",
    "    # Convert the image to grayscale for face detection\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces in the image\n",
    "    faces = detector(gray)\n",
    "    # We take only the first detected face, if exist\n",
    "    if len(faces) == 0:\n",
    "         # Save the final preprocessed image\n",
    "        save_path = image_path.replace(folder_input_path,folder_output_path)+\".jpg\"\n",
    "        # black and white output:\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "        print(\"Image without detected face\", image_path)\n",
    "        continue\n",
    "    face = faces[0]\n",
    "    \n",
    "    # We extract the landmarks   \n",
    "    landmarks = predictor(image, face)\n",
    "    landmarks = np.array([[p.x, p.y] for p in landmarks.parts()])\n",
    "\n",
    "    # Calculate the center of the eyes\n",
    "    left_eye = np.mean(landmarks[36:42], axis=0)\n",
    "    right_eye = np.mean(landmarks[42:48], axis=0)\n",
    "    nose = landmarks[30]\n",
    "\n",
    "    # Calculate the angle between the eyes and the horizontal line\n",
    "    dY = right_eye[1] - left_eye[1]\n",
    "    dX = right_eye[0] - left_eye[0]\n",
    "    angle = np.degrees(np.arctan2(dY, dX))\n",
    "\n",
    "    # Rotate the image around the center of the face rectangle\n",
    "    (x, y, w, h) = (face.left(), face.top(), face.width(), face.height())\n",
    "    center = (x + w // 2, y + h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    aligned_face = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]), flags=cv2.INTER_CUBIC)\n",
    "    if ((aligned_face.shape[0] == 0) or (aligned_face.shape[1] == 0) or (aligned_face.shape[2] == 0)):\n",
    "        continue\n",
    "    \n",
    "    # Re apply the face crop on the aligned image\n",
    "    gray = cv2.cvtColor(aligned_face, cv2.COLOR_BGR2GRAY)\n",
    "    faces_aligned = detector(gray)\n",
    "    if not faces_aligned:\n",
    "        continue\n",
    "    # Modifyers to crop less to capture head fully\n",
    "    reduce = 0.7\n",
    "    increase = 1/0.7\n",
    "    \n",
    "    x, y, w, h = int(faces_aligned[0].left()*reduce), int(faces_aligned[0].top()*reduce), int(faces_aligned[0].width()*increase), int(faces_aligned[0].height()*increase)\n",
    "    processed_face = aligned_face[y:y+h, x:x+w]\n",
    "    if ((processed_face.shape[0] == 0) or (processed_face.shape[1] == 0) or (processed_face.shape[2] == 0)):\n",
    "        continue\n",
    "    \n",
    "    # Save the final preprocessed image\n",
    "    save_path = image_path.replace(folder_input_path,folder_output_path)+\".jpg\"\n",
    "    # black and white output:\n",
    "    cv2.imwrite(save_path, cv2.cvtColor(processed_face, cv2.COLOR_BGR2GRAY)) #cv2.cvtColor(processed_face, cv2.COLOR_BGR2GRAY)\n",
    "    #cv2.imwrite(save_path, face_image)\n",
    "    # print(f\"Face image saved: {save_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To reduce the image size of all images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../raw_data/output_imdb_top100/\"\n",
    "\n",
    "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "\n",
    "images = [f.replace('.jpg', '') for f in file_list]\n",
    "for image_path in images:\n",
    "    img = cv2.imread(image_path+'.jpg')\n",
    "    width = int(img.shape[1])\n",
    "    height = int(img.shape[0])\n",
    "    target_width = 600\n",
    "    if width > target_width:\n",
    "        dim = (target_width, int(height*(target_width/width)))\n",
    "        resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        resized = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR)\n",
    "        Image.fromarray(resized).save(image_path+'.jpg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b88fd1bcfc33f3e877ed5a51499f1885bce5175683b49b371cd530cf79397b4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
