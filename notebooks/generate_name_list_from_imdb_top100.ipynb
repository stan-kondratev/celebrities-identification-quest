{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook is used to fetch the Top-100 of actors and actressess of all time from IMDB top list\n",
    "\n",
    "1. It saves the output into a csv file (list_act.csv) with the following columns: rank, name, imdb_id\n",
    "2. It retrieves images from imdb based on provided list_act.csv and saves them to the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cinemagoer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping from IMDB\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import imdb  # Comes from cinemagoer package\n",
    "from imdb import helpers as hlp\n",
    "import requests\n",
    "import os\n",
    "import unicodedata\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scraping of the best actors and actresses of all time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url list of top 100 actresses and actors from IMDB\n",
    "\n",
    "url_list = [\"https://www.imdb.com/list/ls063784435/\", \"https://www.imdb.com/list/ls050274118/\"] # Url for top 100 actors and top100 actressess\n",
    "\n",
    "\n",
    "# Dictionary with the keys that will be used to store the data in a csv file\n",
    "act_dict = {\n",
    "    \"rank\":[],\n",
    "    \"name\":[],\n",
    "    \"imdb_id\":[]\n",
    "    }\n",
    "\n",
    "for url in url_list:\n",
    "    response = get(url) \n",
    "\n",
    "    # Parse the content of current iteration of request\n",
    "    page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "    movie_containers = page_html.find_all('div', class_ = 'lister-item mode-detail')\n",
    "\n",
    "    for container in movie_containers:\n",
    "        act_dict[\"rank\"].append(container.find('h3', class_ = 'lister-item-header').find('span', class_ = 'lister-item-index unbold text-primary').text.split(\".\")[0])\n",
    "        act_dict[\"name\"].append(container.find('h3', class_ = 'lister-item-header').find(\"a\").text.strip())\n",
    "        act_dict[\"imdb_id\"].append(container.find('h3', class_ = 'lister-item-header').find(\"a\")[\"href\"].split(\"/\")[2])\n",
    "   \n",
    "df_act = pd.DataFrame(act_dict)\n",
    "df_act.to_csv(\"../raw_data/list_act.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list_act.csv file to a dataframe\n",
    "df_act = pd.read_csv(\"../raw_data/list_act.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Retrieval of images based on scraped names and saving to a provided path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia = imdb.Cinemagoer()\n",
    "\n",
    "folder_name = \"output_imdb_top100\"\n",
    "\n",
    "# Remove diacritics from name\n",
    "def strip_accents(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "for actor in df_act[\"imdb_id\"]:\n",
    "    actor_id = int(actor.strip(\"nm\"))\n",
    "    person = ia.get_person(actor_id)\n",
    "    jpg_path = hlp.resizeImage(person[\"headshot\"],crop=\"0.2\")\n",
    "\n",
    "    person_name = \"_\".join(strip_accents(person[\"name\"].lower()).split())+\".jpg\"\n",
    "\n",
    "    target_path = os.path.join(os.getcwd(),\"..\",\"raw_data\", folder_name, person_name)\n",
    "\n",
    "    original = jpg_path\n",
    "    target = target_path\n",
    "\n",
    "    url = jpg_path\n",
    "    \n",
    "    # This statement requests the resource at\n",
    "    # the given link, extracts its contents\n",
    "    # and saves it in a variable\n",
    "    data = requests.get(url).content\n",
    "    \n",
    "    # Opening a new file named img with extension .jpg\n",
    "    # This file would store the data of the image file\n",
    "    f = open(target_path,'wb')\n",
    "    \n",
    "    # Storing the image data inside the data variable to the file\n",
    "    f.write(data)\n",
    "    f.close()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df72ad6b876db13f2ccc9c4ba2add62e572bc168effa3cffd8e6096fc2039355"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
