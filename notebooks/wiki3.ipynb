{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sparqlwrapper\n",
    "# https://rdflib.github.io/sparqlwrapper/\n",
    "\n",
    "# import sys\n",
    "import requests\n",
    "url = 'https://www.wikidata.org/w/api.php'\n",
    "\n",
    "def search_entities(name, url):\n",
    "    \"\"\"\n",
    "    Get the entity id, using a name, by calling the Wiki API. \n",
    "    The output is a list of dict of dictionaries corresponding to the number of\n",
    "    occurances of the given name \n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'action': 'wbsearchentities',\n",
    "        'format': 'json',\n",
    "        'language': 'en',\n",
    "        'search': name\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()['search']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q37079'}, 'image': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/TomCruiseDec08MTV%20cropped.jpg'}, 'occupationLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'film director'}, 'genderLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'male'}, 'bdayLabel': {'type': 'literal', 'value': '1962-07-03T00:00:00Z'}, 'citizenshipLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'United States of America'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q37079'}, 'image': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/TomCruiseDec08MTV%20cropped.jpg'}, 'occupationLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'film producer'}, 'genderLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'male'}, 'bdayLabel': {'type': 'literal', 'value': '1962-07-03T00:00:00Z'}, 'citizenshipLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'United States of America'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q37079'}, 'image': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/TomCruiseDec08MTV%20cropped.jpg'}, 'occupationLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'film actor'}, 'genderLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'male'}, 'bdayLabel': {'type': 'literal', 'value': '1962-07-03T00:00:00Z'}, 'citizenshipLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'United States of America'}}\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import sys\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ?item ?occupationLabel ?image ?genderLabel ?bdayLabel ?citizenshipLabel\n",
    "WHERE \n",
    "{\n",
    "  ?item wdt:P106 ?occupation .\n",
    "  ?item wdt:P21 ?gender .\n",
    "  ?item wdt:P18 ?image .\n",
    "  ?item wdt:P569 ?bday .\n",
    "  ?item wdt:P27 ?citizenship\n",
    "  FILTER(?item = wd:Q37079)\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    \"\"\"\n",
    "    Get's the information from endpoint (wikidata), by submitting a SPAQL query,\n",
    "    returning s corresponding JSON file\n",
    "    \"\"\"\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'uri',\n",
       " 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/Brad%20Pitt%202019%20by%20Glenn%20Francis.jpg'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"results\"][\"bindings\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Get all the names and entity_id\n",
    "data = pd.read_csv(\"../raw_data/list_act.csv\") #read current names from the list_act csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dictionary to ho\n",
    "new_file_dict = {\n",
    "    \"name\":[],\n",
    "    \"wiki_id\":[]\n",
    "}\n",
    "for name in data[\"name\"]:\n",
    "    res = search_entities(name,url=url)[0][\"id\"]\n",
    "    new_file_dict[\"name\"].append(name)\n",
    "    new_file_dict[\"wiki_id\"].append(res)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act = pd.DataFrame(new_file_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act.to_csv(\"../raw_data/celebrity_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df with all the name taken from the df having wiki_id\n",
    "from logic import WikiDataQueryResults as wdr\n",
    "# adding Folder_2 to the system path\n",
    "sys.path.insert(0, '/home/amninder/Desktop/Folder_2')\n",
    "\n",
    "new_df = pd.DataFrame(columns=['itemLabel','item', 'image', 'occupationLabel','genderLabel', 'bdayLabel','citizenshipLabel','dodLabel'])\n",
    "\n",
    "for wiki_id in df_act[\"wiki_id\"]:\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT ?itemLabel ?item ?occupationLabel ?image ?genderLabel ?bdayLabel ?citizenshipLabel ?dodLabel\n",
    "    WHERE \n",
    "    {{\n",
    "    ?item wdt:P106 ?occupation .\n",
    "    ?item wdt:P21 ?gender .\n",
    "    ?item wdt:P18 ?image .\n",
    "    ?item wdt:P569 ?bday .\n",
    "    ?item wdt:P27 ?citizenship .\n",
    "    ?item wdt:P570 ?dod .\n",
    "    FILTER(?item = wd:{wiki_id})\n",
    "    SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    data_extracter = wdr(query)\n",
    "    df = data_extracter.load_as_dataframe()\n",
    "    new_df = pd.concat([new_df,df[0:1]])\n",
    "new_df.to_csv(\"../raw_data/output_wiki/metafile.csv\") #write to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemLabel</th>\n",
       "      <th>item</th>\n",
       "      <th>image</th>\n",
       "      <th>occupationLabel</th>\n",
       "      <th>genderLabel</th>\n",
       "      <th>bdayLabel</th>\n",
       "      <th>citizenshipLabel</th>\n",
       "      <th>dodLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marlene Dietrich</td>\n",
       "      <td>http://www.wikidata.org/entity/Q4612</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>actor</td>\n",
       "      <td>female</td>\n",
       "      <td>1901-12-27T00:00:00Z</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1992-05-06T00:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>http://www.wikidata.org/entity/Q4616</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>actor</td>\n",
       "      <td>female</td>\n",
       "      <td>1926-06-01T00:00:00Z</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1962-08-04T00:00:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          itemLabel                                  item  \\\n",
       "0  Marlene Dietrich  http://www.wikidata.org/entity/Q4612   \n",
       "0    Marilyn Monroe  http://www.wikidata.org/entity/Q4616   \n",
       "\n",
       "                                               image occupationLabel  \\\n",
       "0  http://commons.wikimedia.org/wiki/Special:File...           actor   \n",
       "0  http://commons.wikimedia.org/wiki/Special:File...           actor   \n",
       "\n",
       "  genderLabel             bdayLabel          citizenshipLabel  \\\n",
       "0      female  1901-12-27T00:00:00Z  United States of America   \n",
       "0      female  1926-06-01T00:00:00Z  United States of America   \n",
       "\n",
       "               dodLabel  \n",
       "0  1992-05-06T00:00:00Z  \n",
       "0  1962-08-04T00:00:00Z  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"../raw_data/metafile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "\n",
    "user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1]) #define agent\n",
    "headers = {'User-Agent': user_agent}\n",
    "\n",
    "def strip_accents(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Iterate over all celebrities in df and get image and save to output_wiki\n",
    "for idx, row in new_df.iterrows():\n",
    "    img_url = new_df[\"image\"].iloc[idx]\n",
    "    # person_name = new_df[\"itemLabel\"].iloc[idx]\n",
    "    person_name = \"_\".join(strip_accents(new_df[\"itemLabel\"].iloc[idx].lower()).split())+\".jpg\"\n",
    "    target_path = os.path.join(os.getcwd(),\"raw_data\",\"output_wiki\",person_name)\n",
    "    target_image = target_path\n",
    "    response = requests.get(img_url,stream=True,headers=headers)\n",
    "\n",
    "    if response.status_code:\n",
    "        fp = open(target_image, 'wb')\n",
    "        fp.write(response.content)\n",
    "        fp.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
